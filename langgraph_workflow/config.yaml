# LLMプロバイダー設定
llm_providers:
  # OpenAI設定
  openai:
    name: "OpenAI"
    models:
      gpt-4o:
        name: "GPT-4 Omni"
        max_tokens: 4096
        cost_per_1k_tokens: 0.005
        capabilities: ["text", "vision", "code"]
      gpt-4-turbo:
        name: "GPT-4 Turbo"
        max_tokens: 4096
        cost_per_1k_tokens: 0.01
        capabilities: ["text", "code"]
      gpt-3.5-turbo:
        name: "GPT-3.5 Turbo"
        max_tokens: 4096
        cost_per_1k_tokens: 0.0015
        capabilities: ["text", "code"]
    api_key: "${OPENAI_API_KEY}"
    endpoint: "https://api.openai.com/v1"
    default_model: "gpt-4o"
    
  # Anthropic設定
  anthropic:
    name: "Anthropic"
    models:
      claude-3-opus:
        name: "Claude 3 Opus"
        max_tokens: 4096
        cost_per_1k_tokens: 0.015
        capabilities: ["text", "vision", "code"]
      claude-3-sonnet:
        name: "Claude 3 Sonnet"
        max_tokens: 4096
        cost_per_1k_tokens: 0.003
        capabilities: ["text", "vision", "code"]
      claude-3-haiku:
        name: "Claude 3 Haiku"
        max_tokens: 4096
        cost_per_1k_tokens: 0.00025
        capabilities: ["text", "vision", "code"]
    api_key: "${CLAUDE_API_KEY}"
    endpoint: "https://api.anthropic.com"
    default_model: "claude-3-sonnet"
    
  # Google Gemini設定
  google:
    name: "Google Gemini"
    models:
      gemini-pro:
        name: "Gemini Pro"
        max_tokens: 8192
        cost_per_1k_tokens: 0.0005
        capabilities: ["text", "code"]
      gemini-pro-vision:
        name: "Gemini Pro Vision"
        max_tokens: 8192
        cost_per_1k_tokens: 0.0005
        capabilities: ["text", "vision", "code"]
    api_key: "${GEMINI_API_KEY}"
    endpoint: "https://generativelanguage.googleapis.com"
    default_model: "gemini-pro"
    
  # ローカルモデル設定
  local:
    name: "Local Models"
    models:
      llama-3.1-8b:
        name: "Llama 3.1 8B"
        max_tokens: 4096
        cost_per_1k_tokens: 0.0
        capabilities: ["text", "code"]
        endpoint: "http://localhost:11434"
      qwen2.5-7b:
        name: "Qwen 2.5 7B"
        max_tokens: 4096
        cost_per_1k_tokens: 0.0
        capabilities: ["text", "code"]
        endpoint: "http://localhost:11435"
    api_key: ""
    default_model: "llama-3.1-8b"

# ノードレベルのLLM設定
llm_agents:
  # 分析ノード - Claudeを使用した深い分析
  analyze_viewpoints_modules:
    provider: "anthropic"
    model: "claude-3-sonnet"
    temperature: 0.1
    max_tokens: 2048
    fallback_providers: ["openai", "google"]
    
  # マッチングノード - GPT-4を使用した正確なマッチング
  match_viewpoints:
    provider: "openai"
    model: "gpt-4o"
    temperature: 0.1
    max_tokens: 1024
    fallback_providers: ["anthropic", "google"]
    
  # 语义关联映射节点 - 使用Claude进行深度语义分析
  create_semantic_correlation_map:
    provider: "anthropic"
    model: "claude-3-sonnet"
    temperature: 0.1
    max_tokens: 2048
    fallback_providers: ["openai", "google"]
    
  # 生成ノード - GPT-4を使用した創造的生成
  generate_testcases:
    provider: "openai"
    model: "gpt-4o"
    temperature: 0.3
    max_tokens: 2048
    fallback_providers: ["anthropic", "google"]
    
  # ルーティング推論 - Geminiを使用した論理推論
  route_infer:
    provider: "google"
    model: "gemini-pro"
    temperature: 0.2
    max_tokens: 1024
    fallback_providers: ["openai", "anthropic"]
    
  # クロスページケース - Claudeを使用した複雑な分析
  generate_cross_page_case:
    provider: "anthropic"
    model: "claude-3-sonnet"
    temperature: 0.2
    max_tokens: 2048
    fallback_providers: ["openai", "google"]
    
  # 出力フォーマット - ローカルモデルを使用してコスト削減
  format_output:
    provider: "local"
    model: "llama-3.1-8b"
    temperature: 0.1
    max_tokens: 1024
    fallback_providers: ["openai", "anthropic"]
    
  # 历史测试用例处理 - 使用Claude进行复杂数据处理
  process_historical_cases:
    provider: "anthropic"
    model: "claude-3-sonnet"
    temperature: 0.1
    max_tokens: 2048
    fallback_providers: ["openai", "google"]
    
  # 测试模式提取 - 使用GPT-4进行模式识别
  extract_test_patterns:
    provider: "openai"
    model: "gpt-4o"
    temperature: 0.2
    max_tokens: 2048
    fallback_providers: ["anthropic", "google"]
    
  # 差异分析 - 使用Claude进行细致比较
  analyze_differences:
    provider: "anthropic"
    model: "claude-3-sonnet"
    temperature: 0.1
    max_tokens: 2048
    fallback_providers: ["openai", "google"]
    
  # 覆盖率评估 - 使用GPT-4进行全面评估
  evaluate_coverage:
    provider: "openai"
    model: "gpt-4o"
    temperature: 0.2
    max_tokens: 2048
    fallback_providers: ["anthropic", "google"]

# グローバルLLM戦略
llm_strategy:
  # コスト最適化戦略
  cost_optimization:
    enabled: true
    max_cost_per_request: 0.05  # ドル
    preferred_providers: ["local", "google", "anthropic", "openai"]
    
  # パフォーマンス最適化戦略
  performance_optimization:
    enabled: true
    max_response_time: 30  # 秒
    timeout_fallback: true
    
  # 品質最適化戦略
  quality_optimization:
    enabled: true
    min_quality_score: 0.8
    retry_on_low_quality: true
    
  # 負荷分散戦略
  load_balancing:
    enabled: true
    round_robin: true
    health_check_interval: 60  # 秒

output:
  format: "excel"
  include_mermaid: true
  language: "ja"
  date_format: "YYYY/MM/DD"
  time_format: "HH:mm"

# Redis設定 - PostgreSQLの代替
redis:
  url: "${REDIS_URL:-redis://localhost:6379}"
  db: 0
  max_connections: 10
  socket_timeout: 5
  socket_connect_timeout: 5
  
  # TTL設定
  ttl:
    session: 86400          # 24時間
    node_result: 86400      # 24時間
    feedback: 86400         # 24時間
    workflow_state: 7200    # 2時間
    figma_data: 7200        # 2時間
    viewpoints: 7200        # 2時間
    llm_call: 3600          # 1時間
    cache: 3600             # 1時間
  
  # キャッシュ戦略
  strategy:
    preload_frames: true     # すべてのフレームをプリロード
    cache_by_component: true # コンポーネントタイプ別にキャッシュ
    cache_analysis: true     # 分析結果をキャッシュ
    cache_mappings: true     # マッピング関係をキャッシュ

# ストレージ設定（MinIOをファイルストレージ用に保持）
storage:
  minio_url: "${MINIO_URL}"
  minio_access_key: "${MINIO_ACCESS_KEY}"
  minio_secret_key: "${MINIO_SECRET_KEY}"

logging:
  level: "INFO"
  save_intermediate: true
  language: "ja"

custom:
  case_id_prefix: "TC-"
  language: "ja"
  supported_languages: ["en", "ja"]
  default_language: "ja"
